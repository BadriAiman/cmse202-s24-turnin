{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: right;\"> &#9989; Badri Badrul</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Section 002 - Spring 2024) (90 points total)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be committing and pushing repository changes to a GitHub repository, working with data to build a network graph, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, you'll probably want to make sure you do Part 1 first to ensure that your GitHub repository is working correctly. Let your instructor know right away if you run into issues!\n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. You can also use _your version_ of past CMSE 202 assignments and the CMSE 202 course materials as a resource! **However: The use of any person-to-person communication software or generative AI tools is absolutely not acceptable.** If you are seen accessing your email, using a collaborative cloud storage or document software (e.g. Slack, Google Documents), or generative AIs (e.g. ChatGPT), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please do your best to keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 0: Academic integrity statement\n",
    "\n",
    "Read the following statement and edit the markdown text to put your name in the statement. This is your commitment to doing your own authentic work on this exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I, **BADRI AIMAN KHAN BADRUL ZEMAN KHAN**, affirm that this exam represents my own authetic work, without the use of any unpermitted aids or resources or person-to-person communication. I understand that this exam an an opportunity to showcase my own progress in developing and improving my computational skills and have done my best to demonstrate those skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 1: Add to your Git repository to track your progress on your exam (9 points)\n",
    "\n",
    "Before you get to far along in the exam, you're going to add it to the `cmse202-s24-turnin` repository you created in class so that you can track your progress on the exam and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-s24-turnin` repository and create a new directory called `final`.\n",
    "2. Move this notebook into that **new directory** in your repository, then **add it and commit it to your repository**.\n",
    "1. Finally, to test that everything is working, \"git push\" the file so that it ends up in your GitHub repository.\n",
    "\n",
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" respository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the noteobok, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-s24-turnin`\" repository inside the `final` directory that you just created. Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit.\n",
    "\n",
    "&#9989; **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "gti clone https://github.com/BadriAiman/cmse202-s24-turnin/blob/main/final/CMSE202-Final-Section002-STUDENT.ipynb\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 2: Graph for Game of Thrones (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will look at characters in the book series \"A Song of Ice and Fire\" (\"A Game of Thrones\") by George R. R. Martin, specifically the book \"A Storm of Swords\". The series features a large number of characters in a variety of places around a fantasy world. Some of them appear with each other, while others never meet. We will model these character coappearances as an undirected graph. Every node will be a character and there will be a edge between two characters if they co-appeared (defined as: \"their names appear within 15 words of each other in the text\"). More info about this dataset can be found here https://github.com/melaniewalsh/sample-social-network-datasets/tree/master/sample-datasets/game-of-thrones\n",
    "\n",
    "To get started, download the `GameOfThrones.csv` file from the link below (or D2L) and place it in the same directory as your notebook. \n",
    "\n",
    "`https://raw.githubusercontent.com/skarnik1337/cmse202sec002s24final/main/GameOfThrones.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.1 (2 points)**: Read in the `GameOfThrones.csv` dataset into a `Pandas` `DataFrame` and display the first and last few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GameOfThrones.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Put your code for Question 2.1 here\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m GOT \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGameOfThrones.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GameOfThrones.csv'"
     ]
    }
   ],
   "source": [
    "### Put your code for Question 2.1 here\n",
    "import pandas as pd\n",
    "GOT = pd.read_csv(\"GameOfThrones.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see two columns: `Character1` and `Character2`. Each row contains a pair of characters that coappeared. We will now create an **undirected graph** using this dataset.\n",
    "\n",
    "&#9989; **Question 2.2 (3 points)**: Create a `networkx` `Graph` object which has a vertex for each character and an edge between any pair of characters which are coappear. The resulting graph should now have an edge per row in the dataset and the set of all names should be the set of all nodes.\n",
    "\n",
    "One way to do this is to start with an empty `Graph`. Then, loop through each row of the dataset and add an edge between the two characters listed in that row. There are of course other solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now visualize the graph.\n",
    "\n",
    "&#9989; **Question 2.3 (6 points)**: Make a large `matplotlib` figure and then use the `draw_networkx()` method to draw the graph. Then, make the following modifications to the drawing:\n",
    "\n",
    "1. Label each vertex with the name of the character.\n",
    "2. Pick two different colors. Any node whose degree is at least 18 should be one color and all other nodes should be the other color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### For each part of Question 2.4, use a short amount of networkx code to find answer. Note that you must use the `Graph` object you created along with a networkx method to receive credit, and answers based on using the original csv file, the DataFrame, or the plot in Question 2.3 will not receive credit.\n",
    "\n",
    "Note that your code doesn't need to format the answer in a complete sentence, but the output should not contain any extraneous information.\n",
    "\n",
    "Also, if you couldn't create the `Graph` correctly, you can still receive credit on each part of Question 2.4 by writing code that would have given the correct answer if your `Graph` was correct.\n",
    "\n",
    "&#9989; **Question 2.4.1 (1 point)** How many characters are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.1 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.4.2 (1 point)** True or False?: The characters `Ilyn` and `Joffrey` coappear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.4.3 (1 point)** How many characters coappear with `Daenerys`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.4.4 (1 point)** List all characters who coappear with `Rickon`. \n",
    "\n",
    "**Hint**: The `list()` method and the `all_neighbors()` method in `networkx` will be useful for answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.4 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the distance between two characters as the length of the shortest path between the nodes corresponding to the two characters (i.e. the number of edges in this path, which is one less than the number of nodes).\n",
    "\n",
    "&#9989; **Question 2.4.5 (2 points)**:  What is the distance between `Drogo` and `Walton`?\n",
    "\n",
    "**Hint**: See if you can use a search engine to find a `networkx` method that computes the length of the shortest path between two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.5 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.4.6 (4 points)**: What is the **maximum distance** between a Game of Thrones character and `Robert`?\n",
    "\n",
    "**Hint**: You may want to start by looping through the nodes in the `Graph` you created, computing the distance between that node and `Robert`, and then appending that distance to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.6 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.4.7 (4 points)**: Which Game of Thrones **character** is farthest from `Lancel` (i.e. which character has the greatest distance to `Lancel`)? \n",
    "\n",
    "**Note**: You may assume there is a unique farthest character (i.e. no ties for the greatest distance).\n",
    "\n",
    "**Hint**: Similarly to Question 2.4.7, you may want to start by looping through the nodes in the `Graph` you created, computing the distance between that node and `Lancel`, and then appending that distance to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.7 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 2**\", and push the changes to GitHub.\n",
    "\n",
    "\n",
    "If committing and/or pushing isn't working for you, write down the complete commands in this cell that would have committed your changes (with the commit message) and pushed them to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 3: Regression on synthetic data (27 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will generate synthetic data according to a known model. First, you will perform linear regression on the data and interperate the results. Next, you will perform polynomial regression and interperate the results. Finally, you will perform polynomial regression, but with a reduced model, and interperate the results.\n",
    "\n",
    "\n",
    "To get started, run the cell below to generate two `numpy` arrays `x_data` and `y_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# DO NOT EDIT THIS CELL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "x_data = np.random.uniform(-1,1,size=(101,))\n",
    "y_data = np.sin(np.pi*x_data)+0.15*np.random.normal(size=(101,))\n",
    "# DO NOT EDIT THIS CELL\n",
    "# DO NOT EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.1 (1 point)**: Before you get too caried away with regression analysis, make a scatterplot of this data with `y_data` on the vertical axis and `x_data` on the horizontal axis. This will help you see what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for Question 3.1 here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.2 (2 points)**: Looking at the plot you made in Question 3.1, is a linear model appropriate for this data? Briefly justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.3 (4 points)**: Regardless of your answer to Question 3.2, we will try linear regression anyway.\n",
    "\n",
    "**Do This**: Using `OLS()` in `statsmodels`, fit a linear model of the form $\\widehat{y} = Ax+B$ to the data. \n",
    "\n",
    "*Hint*: Don't forget the constant term. Also, you might want to have the original variable `x_data` handy for Question 3.5, so be careful not to overwrite it when using the `add_constant()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for Question 3.3 here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.4 (2 points)**: Looking at the results summary, what is the equation of your best fit linear model? You may round the coefficents to a few decimal places when writing down your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.5 (5 points)**: Now, we will use OLS to fit a degree-$6$ polynomial model to this data. If you get stuck, you may want to look at the Day-14 PCA. \n",
    "\n",
    "**Do the following**: \n",
    "* First, construct a `Pandas` `DataFrame` whose columns are the monomial features $1, x, x^2, x^3, x^4, x^5, x^6$. In other words, this `DataFrame` should have 7 columns. The 0th column has all 1's. The 1st column should have the values in `x_data`. The 2nd column should have the values in `x_data` raised to the 2nd power, ..., and the 6th column should have the values in `x_data` raised to the 6th power.\n",
    "* Then, perform OLS using `statsmodels`, and display the results summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for Question 3.5 here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.6 (2 points)**: Looking at just the results summaries in Question 3.5 and Question 3.3, is our degree-$6$ polynomial significantly better than our linear model? **Justify your answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.7 (2 points)**: Looking at just the results summary in Question 3.5 (and not at how the synthetic data was generated), which of the monomial features $1, x, x^2, x^3, x^4, x^5, x^6$ are statistically significant and which are not statistically significant? **Again, justify your answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.8 (2 points)**: In Question 3.7, you should have observed a pattern to which monomial features were statistically significant and which were not. The data points $(x_i,y_i)$ were generated according to the sinusoidal model $y_i = \\sin(\\pi x_i) + \\text{noise}_i$. With this in mind, give an explaination for this pattern.\n",
    "\n",
    "*Hint*: Think about what kind of symmetry $y = \\sin(\\pi x)$ has about $x = 0$ as well as what kind of symmetry each of the monomials $1, x, x^2, x^3, x^4, x^5, x^6$ has about $x = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.9 (5 points)**: Now, use OLS to fit a polynomial model using only the monomial features which you identified as being statistically significant. Again, print out the results summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for Question 3.9 here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.10 (2 points)**: How well did your reduced polynomial model (from Question 3.9) fit the data compared to the full degree-$6$ polynomial model (from Question 3.5)? Give some quantitative justification for this answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 3**\", and push the changes to GitHub.\n",
    "\n",
    "\n",
    "If committing and/or pushing isn't working for you, write down the complete commands in this cell that would have committed your changes (with the commit message) and pushed them to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 4: Support vector machine (SVM) classification (29 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will use a support vector machine (SVM) classifier to identify seed varieties based on various seed measurements. We will be using the UC Irvine Machine Learning Repository Seeds Dataset. More info about this dataset can be found here https://archive.ics.uci.edu/dataset/236/seeds. \n",
    "\n",
    "To get started, download the `Seeds.csv` file from the link below (or D2L) and place it in the same directory as your notebook. \n",
    "\n",
    "`https://raw.githubusercontent.com/skarnik1337/cmse202sec002s24final/main/Seeds.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.1 (2 points)**: Read in the `Seeds.csv` dataset into a `Pandas` `DataFrame` and display the first and last few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.1 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.2 (2 points)**: Our goal is to classify the `Variety` of the seed given the features `Area`, `Perimeter`, `Compactness`, `Kernel Length`, `Kernel Width`, `Asymmerty` and `Groove Length`. Create a variable with all of the columns of the `DataFrame` except for `Variety`,  and another variable with just the `Variety` column of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is properly loaded into Python, we need to perform a **train-test-split** so that we can build our SVM classifier and test it.\n",
    "\n",
    "&#9989; **Question 4.3 (4 points)**: Use the `train_test_split()` method from `sklearn.model_selection` like we did in class. Use a `train_size` of `0.75` and `random_state` of `161803`. You should now have training features, testing features, training labels, and testing labels. Finally, **print the shape of your training features, training labels, testing features, and testing labels** to verify that your train-test-split did what it was supposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.4 (6 points)**: Fit an SVM classifier (using the `sklearn` `SVC` class) to the dataset. Use a `linear` kernel and set the hyper-parameter to be `C=0.001.` Then **fit the SVM using your training set** and use the resulting SVM to **predict the labels for the testing set** so you get predicted labels for the testing set. Finally, **print the fit statistics** using the `confusion_matrix()` and `classification_report()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.4 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.5 (2 points)**: Create a second SVM classifier and test it by repeating your work from Question 4.4, but this time set the hyper-parameter to be `C=100.` Again, **print the fit statistics** using the `confusion_matrix()` and `classification_report()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.5 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.6 (6 points)**: Interpret the outputs of your classification reports and the confusion matrices by answering these questions (provide at least a couple sentences each for full credit): \n",
    "\n",
    "* Of the 53 seeds in the testing set, how many were misclassified by the first SVM (`C = 0.001`)? How many were misclassified by the second SVM (`C = 100`)? **Explain how you figured out the number of misclassifications**. \n",
    "\n",
    "* For just the first SVM (`C = 0.001`) what were the **precision** and **recall** for just the `Canadian` class? Explain in complete sentences what both of these numbers mean **in the context of this dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "&#9989; **Question 4.7 (1 point)**: Suppose we wanted to try fitting a Support Vector Classifier for multiple choices of the kernel function and multiple choices for the values of the hyperparameter(s) (instead of just using a `linear` kernel with one value of `C`). We could write code with nested for loops to repeat the procedure with every combination of kernel function and hyperparameter value(s) we wanted to try. Name a method built into sklearn that will do this automatically. (We used this on an in-class assignment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.8 (3 points)**: Both of the images below show the same two-dimensional dataset with two classes (solid blue squares and unfilled red circles) along with the decision boundary of a linear classifier. One classifier was generated via the Perceptron Learning Algorithm, and the other used a Support Vector Classifier. Which one is which? **Justify your answer!**\n",
    "\n",
    "Classifier A          | | Classifier B\n",
    ":-------------------------:|:---:|:-------------------------:\n",
    "![](https://i.ibb.co/R2BBsDC/Datapoints1-A.png)  | |  ![](https://i.ibb.co/mb9vcq4/Datapoints1-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.9 (3 points)**: Both of the images below show the same two-dimensional dataset with two classes (solid blue squares and unfilled red circles) along with the decision boundary of a linear Support Vector Classifier. One used the hyperparameter `C = 0.1`, and the other used the hyperparameter `C = 1000`. Which one is which? **Justify your answer!**\n",
    "\n",
    "Classifier X          | | Classifier Y\n",
    ":-------------------------:|:---:|:-------------------------:\n",
    "![](https://i.ibb.co/7pPCRwh/Datapoints2-A.png)  | |  ![](https://i.ibb.co/LSMBXzd/Datapoints2-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 4**\", and push the changes to GitHub.\n",
    "\n",
    "\n",
    "If committing and/or pushing isn't working for you, write down the complete commands in this cell that would have committed your changes (with the commit message) and pushed them to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Final!\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub (or that you wrote down the commands that would have done that after each part). Also upload a copy of this notebook to the dropbox on D2L in case something went wrong with your repository or if you couldn't get the repository to work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
